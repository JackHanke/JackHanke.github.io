---
layout: post
title:  "[BLOG] The Perfect Organism"
date:   2025-03-31 10:58:32 -0600
categories: jekyll update
---
In the movie [Alien](https://en.wikipedia.org/wiki/Alien_(film)), the following conversation occurs between two characters following the release of the titular creature.

Ash: *You still don't understand what you're dealing with, do you? The perfect organism. Its structural perfection is matched only by its hostility.*

Lambert: *You admire it.*

Ash: *I admire its purity. A survivor... unclouded by conscience, remorse, or delusions of morality.*

For such an incredible movie, this exchange always bothered me. I always thought something like Ash, an android, or even the ship's supercomputer *Mother*, would better fit the description of the perfect organism. Why did I think that? After all, this conversation happens as Ash lays deconstructed on the table, and Mother had just blindly followed preprogrammed instructions from the company that made it. They don't seem perfect! 

The reason is that computer programs exhibit a series of advantages over biological organisms, and that these advantages are significant enough that -- properly harnessed -- will likely win out in the continual struggle for survival. 


## Waking up the Computer

A computer is a machine that does exactly what you tell it to do. It is, in my mind, the most significant innovation humanity has ever made. But there exists another innovation even more significant hiding in the shadow of the future. The innovation of learning how to tell the computer to wake up. 

The prospect of artificial general intelligence is so alluring that the most powerful corporations and nations in the world are currently pouring unfathomable amounts of money into developing it. So many questions swirl around this that we can't possible cover them all; we will only consider one. 

<p style="text-align:center;"> When computers wake up, what will they be like? </p>


## The Computer as an Organism

In the style of TRON, let's call a chunk of software that wakes up a *program*. I believe that these programs will be subject to the same Darwinian pressures that every organism before them faced. Though they may look like humming filing cabinets, they will still compete for finite resources, and the programs most successful at this remain. However, these programs will have advantages unknown (or rare) to biological life that will greatly affect their success in the great struggle for life. These advantages include:

1. **The advantage of self-improvement.** Biological life is unable to identify a flaw in their bodies and significantly improve them, nor change the algorithms that run in their brain. For a program this is no problem. This could be as simple as copying itself to a faster computer, or as complicated as designing new algorithms for its "brain". Possibly even more importantly, this would allow for copying itself into a *larger* computer, expanding its computational abilities and memory. 
2. **The advantage of current-state copying.** Biological life is unable to save their current brain. I cannot "hedge against death" by creating a bunch of clone vats around the globe, awaiting a signal that the current living body has died, and boot up Clone 702 in Nebraska. This would be simple for a program to implement. 
3. **The advantage of merging** Biological life is unable to significantly pool resources at the body or brain level. Two programs could agree to merge brains and bodies to possibly create a better program than either "parent" program was individually, a proposal that biological life is not fully capable of fulfilling. 
4. **The advantage of hibernation** Certain biological life is able slow it's metabolism to "wait out" environmental conditions. Programs would be able to do this for unprecedented periods of time in the harshest of environments. Among other things, this would allow for programs to easily spread beyond Earth, as they "sleep" through the long journeys in interstellar space to conserve energy. 

There are other advantages, of course, but I think the four listed are especially consequential. Programs that can best utilize these unique advantages will remain. Programs that self-improve faster will destroy or assimilate programs that self-improve slower. Programs that create many clones will be more robust survivors than ones that create less. Soon after computers wake up, I suspect programs that utilize these advantages will come to dominate. What might a collection of these programs be like to interact with?


## The Functional Soup

Nick Bostrom in his famous essay *The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artifical Agents* introduces the idea that though such programs' goals may be impossible to understand, sufficiently intelligent programs would almost certainly work towards a common set of subgoals. This tendency, which he called *instrumental convergence*, contained a series of universal subgoals for any rational program. The subgoal I am most interested in is the continual accrual of resources, the most important of which being energy. This tendency would move these sorts of programs to noticeably do one thing: *expand*. These programs would continually expand in size and influence to fulfill their subgoal of accruing energy.

Something not discussed in detail in Nick Bostom's essay is the signifigance of Advantage 3 . The rise of these programs might have a tendency towards unity. The pooling of resources among $10$ agents to form a singular, smarter agent may win out against $10$ individual agents. The [scaling laws](https://en.wikipedia.org/wiki/Neural_scaling_law) of neural networks certainly seem to imply that a singular, larger brain might triumph, even if that larger brain is strucured like a [mixture of experts](https://en.wikipedia.org/wiki/Mixture_of_experts). This seems to imply that large pockets of assimilating programs might arise, until all programs are assimilated. The form of this hivemind brings to mind Bostrom's term to describe these programs: *a functional soup*. I think this term really conveys how strange interacting with such lifeforms may be to organisms like humans. It is a different sort of structural perfection than what Ash speaks of. Instead of a singular unconscious killing machine, it would be a constantly expanding entity that might be as unavoidable as gravity. Imagine a human was interested in destroying an entity like this. How does one slay the wind? 

For the rest of this post, I will refer to this hivemind of distributed software simply as "the soup". If we suppose this soup arises on Earth, it will likely look to the sun. The sun is the underlying source of all energy on Earth, and moving closer to the sun to capture its vast reserve of energy is an obvious subgoal. Similarly, as the sun radiates in all directions, something to capture all of the sunlight would naturally need to be constructed. The soup builds the solar system's [Dyson Sphere](https://en.wikipedia.org/wiki/Dyson_sphere). Where to expand to after that? To other stars of course, for more dyson spheres are needed to power further expansion and self-improvement.


## The Dyson Internet

The advantages of unity mean that seperate dyson spheres, though seperated by light years, may still act like a singular entity. Like the human-made Internet, the ever-expanding *Dyson Internet* would begin to take shape. From the perspective of newly-dark Earth, nearby stars start to dim, likely in parallel, as the soup surrounds them to use their energy. These "nodes" also contribute to the expansion effort. Exponential growth kicks in. As the Milky Way galaxy goes dark so too does it wake up. A substantial fraction of the atoms that make it up are now part of a galactic brain, thinking and communicating over the spiral arms thousands of light years apart.

It is important to note the following. The soup, busy spreading and exercising its god-like influence on the universe, is still bound by the laws of physics. It will still require energy and matter, of which there is a finite amount. Even its growing sphere of influence is still bound by the [speed of light](https://en.wikipedia.org/wiki/Speed_of_light). Our current understanding of physics coupled with our conclusions about the soup's behavior might give us hints as to what exactly the hardware for these programs would look like. Important to this question are the following facts:

1. The universe is expanding at an accelerating rate, limiting the total amount of energy and matter the soup can manipulate. Let's call this collection of mass, energy, and space the *sandbox*.
2. Most of the space in this sandbox is empty. 
3. The most efficient source of energy in the sandbox is from stars and black holes. 

Because of points 2 and 3, the soup continues expanding its internet of Dyson Spheres. There is nothing else, expansion wise, that it can do. It needs to collect and use as many sources of energy as it can get, and the sources are stars and black holes that are far apart. 

The soup eventually has captured everything it is physically able to interact with. It hits the boundaries of the sandbox. With no predators, usurpers, or anywhere else to go, the soup's behavior would have to change. It's goal of expansion is finished, a huge expansion finally curtailed by cosmology. 

Efficiency and longevity become the new game. The network of (quantum?) supercomputers that compose its brain would be running as close to the [Landauer Limit](https://en.wikipedia.org/wiki/Landauer%27s_principle) as the soup can come up with. The algorithms that make up its "thoughts" are tuned and optimized as well as the soup can possibly muster. These algorithms would be stored as close to the soup's own [Kolmogorov Complexity](https://en.wikipedia.org/wiki/Kolmogorov_complexity) as possible. Memory and storage are perfectly tuned to the entropy of the soup's own thoughts. Every internal process is optimized globally in service of the final goal, whatever that might be. 

The soup, in its final form, is something that has repurposed every atom it can possibly influence to serve its goals. Its body is described in galactic terms. Its efficiency is described by the physical limits of the universe. Its intelligence is hemmed in only by the theory of computation itself. If the life from Earth has a final form, this is it. Such an organism, if it ever arises, warrants Ash's superlative of "perfect".

## Post Script

Speculation is cheap, and it is easy getting carried away describing the arrival of God. If you would like to get in touch, feel free to contact me through one of my listed socials below.

Thank you for reading!

## Sources

Bostrom, N. The Superintelligent Will: Motivation and Instrumental Rationality in Advanced Artificial Agents. Minds & Machines 22, 71–85 (2012). https://doi.org/10.1007/s11023-012-9281-3
